/**
 * Example: Streaming Responses with CodexProvider
 *
 * This example demonstrates how to use streaming responses in the OpenAI Agents framework
 * with CodexProvider. Streaming allows you to receive real-time updates as the agent
 * generates its response.
 *
 * Based on OpenAI Agents SDK documentation:
 * https://openai.github.io/openai-agents-js/guides/streaming
 *
 * Installation:
 * ```bash
 * npm install @codex-native/sdk @openai/agents
 * ```
 *
 * Usage:
 * ```bash
 * npx tsx examples/agents/agents-streaming.ts
 * ```
 *
 * Key features demonstrated:
 * - Real-time streaming deltas
 * - Handling different stream event types
 * - Token usage tracking
 * - Progress indicators
 * - Using CodexProvider as the model backend
 */

import os from 'node:os';
import path from 'node:path';
import { promises as fs } from 'node:fs';
import { Agent, run } from '@openai/agents';
import { CodexProvider } from '../../src/index';
import { runExampleStep } from '../utils';

async function main() {
  console.log('üåä Streaming Responses with CodexProvider\n');
  console.log('This example demonstrates real-time streaming of agent responses.\n');

  // Create a temporary directory to avoid loading workspace AGENTS.md
  const tmpDir = await fs.mkdtemp(path.join(os.tmpdir(), 'codex-streaming-example-'));
  console.log(`Using temporary directory: ${tmpDir}\n`);

  // Create Codex provider
  const codexProvider = new CodexProvider({
    defaultModel: 'gpt-5-codex',
    workingDirectory: tmpDir,
    skipGitRepoCheck: true,
  });

  const codexModel = await codexProvider.getModel();

  // ============================================================================
  // Example 1: Basic Streaming
  // ============================================================================
  console.log('Example 1: Basic Streaming');
  console.log('‚îÄ'.repeat(60));

  const streamingAgent = new Agent({
    name: 'StreamingAgent',
    model: codexModel,
    instructions: 'You are a helpful assistant. Provide detailed, informative responses.',
  });

  console.log('\nQuery: "Explain how streaming works in AI agents"\n');
  console.log('[Streaming Response]\n');

  const stream1 = await run(streamingAgent, 'Explain how streaming works in AI agents', {
    stream: true,
  });

  if (stream1) {
    let accumulatedText = '';
    let tokenCount = 0;

    for await (const ev of stream1 as any) {
      const event: any = ev;
      switch (event.type) {
        case 'response_started':
          console.log('üì° Response started...\n');
          break;

        case 'output_text_delta':
          // Print deltas as they arrive
          process.stdout.write(event.delta);
          accumulatedText += event.delta;
          tokenCount += event.delta.split(/\s+/).length;
          break;

        // Optional: output_text_done may be emitted
        case 'output_text_done':
          console.log('\n\n‚úì Text output completed');
          if (accumulatedText.trim().length > 0) {
            console.log('\n[Final text]');
            console.log(accumulatedText.trim());
          } else if ('text' in event && typeof (event as any).text === 'string') {
            console.log('\n[Final text]');
            console.log((event as any).text);
          }
          break;

        case 'reasoning_delta':
          // Reasoning deltas (if supported)
          process.stdout.write(`[Reasoning] ${event.delta}`);
          break;

        case 'reasoning_done':
          console.log('\n‚úì Reasoning completed');
          break;

        case 'response_done':
          console.log('\n\n‚úì Text output completed');
          if (accumulatedText.trim().length > 0) {
            console.log('\n[Final text]');
            console.log(accumulatedText.trim());
          }
          console.log('\nüìä Final Statistics:');
          console.log(`  Total tokens: ${event.response.usage.totalTokens}`);
          console.log(`  Input tokens: ${event.response.usage.inputTokens}`);
          console.log(`  Output tokens: ${event.response.usage.outputTokens}`);
          break;

        case 'error':
          console.error('\n‚úó Error:', event.error.message);
          break;
      }
    }

    console.log('\n‚úì Example 1 completed');
  } else {
    console.log('Skipping Example 1 due to a connection issue.');
  }


  // ============================================================================
  // Example 2: Streaming with Progress Indicator
  // ============================================================================
  console.log('\n\nExample 2: Streaming with Progress Indicator');
  console.log('‚îÄ'.repeat(60));

  const progressAgent = new Agent({
    name: 'ProgressAgent',
    model: codexModel,
    instructions: 'You are a coding assistant. Write clear, well-documented code.',
  });

  console.log('\nQuery: "Write a function to calculate fibonacci numbers"\n');
  console.log('[Streaming with Progress]\n');

  const stream2 = await run(progressAgent, 'Write a function to calculate fibonacci numbers', {
    stream: true,
  });

  if (stream2) {
    let chunkCount = 0;
    let lastUpdate = Date.now();

    for await (const ev of stream2 as any) {
      const event: any = ev;
      switch (event.type) {
        case 'response_started':
          console.log('‚è≥ Starting response generation...\n');
          break;

        case 'output_text_delta': {
          chunkCount++;
          const now = Date.now();
          // Update progress indicator every 500ms
          if (now - lastUpdate > 500) {
            process.stdout.write(`\rüìù Received ${chunkCount} chunks... `);
            lastUpdate = now;
          }
          // Still print the actual content
          process.stdout.write(event.delta);
          break;
        }

        case 'output_text_done':
          console.log(`\n\n‚úì Completed (${chunkCount} chunks)`);
          // We may not have deltas; print final text if available on event
          if ('text' in event && typeof (event as any).text === 'string' && (event as any).text.trim()) {
            console.log('\n[Final text]');
            console.log((event as any).text.trim());
          }
          break;

        case 'response_done':
          console.log('\nüìä Usage:');
          console.log(`  Input: ${event.response.usage.inputTokens} tokens`);
          console.log(`  Output: ${event.response.usage.outputTokens} tokens`);
          console.log(`  Total: ${event.response.usage.totalTokens} tokens`);
          break;
      }
    }

    console.log('\n‚úì Example 2 completed');
  } else {
    console.log('Skipping Example 2 due to a connection issue.');
  }


  // ============================================================================
  // Example 3: Streaming with Custom Processing
  // ============================================================================
  console.log('\n\nExample 3: Streaming with Custom Processing');
  console.log('‚îÄ'.repeat(60));

  const customAgent = new Agent({
    name: 'CustomAgent',
    model: codexModel,
    instructions: 'You are a helpful assistant that provides structured information.',
  });

  console.log('\nQuery: "List the benefits of using streaming in AI applications"\n');
  console.log('[Custom Processing]\n');

  const stream3 = await run(customAgent, 'List the benefits of using streaming in AI applications', {
    stream: true,
  });

  if (stream3) {
    const lines: string[] = [];
    let currentLine = '';

    for await (const ev of stream3 as any) {
      const event: any = ev;
      switch (event.type) {
        case 'output_text_delta':
          currentLine += event.delta;
          // Process line by line
          if (event.delta.includes('\n')) {
            const parts = currentLine.split('\n');
            // Add all but the last part (which might be incomplete)
            for (let i = 0; i < parts.length - 1; i++) {
              if (parts[i]!.trim()) {
                lines.push(parts[i]!);
                console.log(`  ${lines.length}. ${parts[i]!.trim()}`);
              }
            }
            currentLine = parts[parts.length - 1]!;
          }
          break;

        case 'output_text_done':
          if (currentLine.trim()) {
            lines.push(currentLine.trim());
            console.log(`‚Ä¢ ${currentLine.trim()}`);
          }
          console.log('\n‚úì Completed custom processing');
          break;

        case 'response_done':
          if (currentLine.trim()) {
            lines.push(currentLine.trim());
          }
          console.log('\nüìÑ Structured Summary:');
          lines.forEach((line, index) => {
            console.log(`  ${index + 1}. ${line}`);
          });
          break;
      }
    }

    console.log('\n‚úì Example 3 completed');
  } else {
    console.log('Skipping Example 3 due to a connection issue.');
  }


  // ============================================================================
  // Example 4: Error Handling in Streaming
  // ============================================================================
  console.log('\n\nExample 4: Error Handling in Streaming');
  console.log('‚îÄ'.repeat(60));

  const errorHandlingAgent = new Agent({
    name: 'ErrorHandlingAgent',
    model: codexModel,
    instructions: 'You are a helpful assistant.',
  });

  console.log('\nQuery: "Explain error handling in streaming"\n');
  console.log('[Error Handling]\n');

  const stream4 = await run(errorHandlingAgent, 'Explain error handling in streaming', {
    stream: true,
  });

  if (stream4) {
    let hasError = false;

    try {
      for await (const ev of stream4 as any) {
        const event: any = ev;
        switch (event.type) {
          case 'output_text_delta':
            process.stdout.write(event.delta);
            break;

          case 'error':
            hasError = true;
            console.error('\n\n‚úó Streaming error:', event.error.message);
            break;

          case 'response_done':
            if (!hasError) {
              console.log('\n\n‚úì Stream completed successfully');
            }
            break;
        }
      }
    } catch (error) {
      console.error(
        '\n\n‚úó Fatal error during streaming:',
        error instanceof Error ? error.message : String(error),
      );
    }

    console.log('\n‚úì Example 4 completed');
  } else {
    console.log('Skipping Example 4 due to a connection issue.');
  }

  // ============================================================================
  // Summary
  // ============================================================================
  console.log('\n\n' + '='.repeat(60));
  console.log('üìã Summary');
  console.log('='.repeat(60));
  console.log('\nKey takeaways:');
  console.log('  ‚Ä¢ Streaming provides real-time updates as responses are generated');
  console.log('  ‚Ä¢ Use run() to obtain StreamedRunResult for streaming flows');
  console.log('  ‚Ä¢ Call run(agent, input, { stream: true }) to enable streaming');
  console.log('  ‚Ä¢ Handle different event types: deltas, done, errors');
  console.log('  ‚Ä¢ CodexProvider supports full streaming capabilities');
  console.log('  ‚Ä¢ Streaming enables better UX with progress indicators');
  console.log('\nStream event types:');
  console.log('  ‚Ä¢ response_started - Stream began');
  console.log('  ‚Ä¢ output_text_delta - Text chunk received');
  console.log('  ‚Ä¢ output_text_done - Text output completed');
  console.log('  ‚Ä¢ reasoning_delta - Reasoning chunk (if supported)');
  console.log('  ‚Ä¢ reasoning_done - Reasoning completed');
  console.log('  ‚Ä¢ response_done - Full response with usage stats');
  console.log('  ‚Ä¢ error - Error occurred');
  console.log('\nFor more information, see:');
  console.log('  https://openai.github.io/openai-agents-js/guides/streaming');

  // Cleanup
  try {
    await fs.rm(tmpDir, { recursive: true, force: true });
  } catch (e) {
    // Ignore cleanup errors
  }
}

// Run if executed directly
if (require.main === module) {
  main()
    .then(() => {
      process.exit(0);
    })
    .catch((error) => {
      console.error('Fatal error:', error);
      process.exit(1);
    });
}

export { main };

