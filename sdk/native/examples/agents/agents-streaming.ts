/**
 * Example: Streaming Responses with CodexProvider
 *
 * This example demonstrates how to use streaming responses in the OpenAI Agents framework
 * with CodexProvider. Streaming allows you to receive real-time updates as the agent
 * generates its response.
 *
 * Based on OpenAI Agents SDK documentation:
 * https://openai.github.io/openai-agents-js/guides/streaming
 *
 * Installation:
 * ```bash
 * npm install @codex-native/sdk @openai/agents
 * ```
 *
 * Usage:
 * ```bash
 * npx tsx examples/agents/agents-streaming.ts
 * ```
 *
 * Key features demonstrated:
 * - Real-time streaming deltas
 * - Handling different stream event types
 * - Token usage tracking
 * - Progress indicators
 * - Using CodexProvider as the model backend
 */

import os from 'node:os';
import path from 'node:path';
import { promises as fs } from 'node:fs';
import { Agent, run } from '@openai/agents';
import { CodexProvider } from '../../src/index';
import { runExampleStep } from '../utils';

async function main() {
  console.log('ðŸŒŠ Streaming Responses with CodexProvider\n');
  console.log('This example demonstrates real-time streaming of agent responses.\n');

  // Create a temporary directory to avoid loading workspace AGENTS.md
  const tmpDir = await fs.mkdtemp(path.join(os.tmpdir(), 'codex-streaming-example-'));
  console.log(`Using temporary directory: ${tmpDir}\n`);

  // Create Codex provider
  const codexProvider = new CodexProvider({
    defaultModel: 'gpt-5-codex',
    workingDirectory: tmpDir,
    skipGitRepoCheck: true,
  });

  const codexModel = await codexProvider.getModel();

  // ============================================================================
  // Example 1: Basic Streaming
  // ============================================================================
  console.log('Example 1: Basic Streaming');
  console.log('â”€'.repeat(60));

  const streamingAgent = new Agent({
    name: 'StreamingAgent',
    model: codexModel,
    instructions: 'You are a helpful assistant. Provide detailed, informative responses.',
  });

  console.log('\nQuery: "Explain how streaming works in AI agents"\n');
  console.log('[Streaming Response]\n');

  const stream1 = await runExampleStep('Basic streaming run', () =>
    run(streamingAgent, 'Explain how streaming works in AI agents')
  );
  const stream1 = await run(streamingAgent, 'Explain how streaming works in AI agents', {
    stream: true,
  });

  if (stream1) {
    let accumulatedText = '';
    let tokenCount = 0;

    for await (const event of stream1.events) {
      switch (event.type) {
        case 'response_started':
          console.log('ðŸ“¡ Response started...\n');
          break;
  for await (const event of stream1) {
    switch (event.type) {
      case 'response_started':
        console.log('ðŸ“¡ Response started...\n');
        break;

        case 'output_text_delta':
          // Print deltas as they arrive
          process.stdout.write(event.delta);
          accumulatedText += event.delta;
          tokenCount += event.delta.split(/\s+/).length;
          break;

        case 'output_text_done':
          console.log('\n\nâœ“ Text output completed');
          break;

        case 'reasoning_delta':
          // Reasoning deltas (if supported)
          process.stdout.write(`[Reasoning] ${event.delta}`);
          break;

        case 'reasoning_done':
          console.log('\nâœ“ Reasoning completed');
          break;

        case 'response_done':
          console.log('\nðŸ“Š Final Statistics:');
          console.log(`  Total tokens: ${event.response.usage.totalTokens}`);
          console.log(`  Input tokens: ${event.response.usage.inputTokens}`);
          console.log(`  Output tokens: ${event.response.usage.outputTokens}`);
          break;

        case 'error':
          console.error('\nâœ— Error:', event.error.message);
          break;
      }
    }

    console.log('\nâœ“ Example 1 completed');
  } else {
    console.log('Skipping Example 1 due to a connection issue.');
  }


  // ============================================================================
  // Example 2: Streaming with Progress Indicator
  // ============================================================================
  console.log('\n\nExample 2: Streaming with Progress Indicator');
  console.log('â”€'.repeat(60));

  const progressAgent = new Agent({
    name: 'ProgressAgent',
    model: codexModel,
    instructions: 'You are a coding assistant. Write clear, well-documented code.',
  });

  console.log('\nQuery: "Write a function to calculate fibonacci numbers"\n');
  console.log('[Streaming with Progress]\n');

  const stream2 = await runExampleStep('Progress streaming run', () =>
    run(progressAgent, 'Write a function to calculate fibonacci numbers')
  );
  const stream2 = await run(progressAgent, 'Write a function to calculate fibonacci numbers', {
    stream: true,
  });

  if (stream2) {
    let chunkCount = 0;
    let lastUpdate = Date.now();

    for await (const event of stream2.events) {
      switch (event.type) {
        case 'response_started':
          console.log('â³ Starting response generation...\n');
          break;
  for await (const event of stream2) {
    switch (event.type) {
      case 'response_started':
        console.log('â³ Starting response generation...\n');
        break;

        case 'output_text_delta':
          chunkCount++;
          const now = Date.now();
          // Update progress indicator every 500ms
          if (now - lastUpdate > 500) {
            process.stdout.write(`\rðŸ“ Received ${chunkCount} chunks... `);
            lastUpdate = now;
          }
          // Still print the actual content
          process.stdout.write(event.delta);
          break;

        case 'output_text_done':
          console.log(`\n\nâœ“ Completed (${chunkCount} chunks)`);
          break;

        case 'response_done':
          console.log('\nðŸ“Š Usage:');
          console.log(`  Input: ${event.response.usage.inputTokens} tokens`);
          console.log(`  Output: ${event.response.usage.outputTokens} tokens`);
          console.log(`  Total: ${event.response.usage.totalTokens} tokens`);
          break;
      }
    }

    console.log('\nâœ“ Example 2 completed');
  } else {
    console.log('Skipping Example 2 due to a connection issue.');
  }


  // ============================================================================
  // Example 3: Streaming with Custom Processing
  // ============================================================================
  console.log('\n\nExample 3: Streaming with Custom Processing');
  console.log('â”€'.repeat(60));

  const customAgent = new Agent({
    name: 'CustomAgent',
    model: codexModel,
    instructions: 'You are a helpful assistant that provides structured information.',
  });

  console.log('\nQuery: "List the benefits of using streaming in AI applications"\n');
  console.log('[Custom Processing]\n');

  const stream3 = await runExampleStep('Custom processing streaming run', () =>
    run(
      customAgent,
      'List the benefits of using streaming in AI applications'
    )
  const stream3 = await run(
    customAgent,
    'List the benefits of using streaming in AI applications',
    { stream: true }
  );

  if (stream3) {
    const lines: string[] = [];
    let currentLine = '';

    for await (const event of stream3.events) {
      switch (event.type) {
        case 'output_text_delta':
          currentLine += event.delta;
          // Process line by line
          if (event.delta.includes('\n')) {
            const parts = currentLine.split('\n');
            // Add all but the last part (which might be incomplete)
            for (let i = 0; i < parts.length - 1; i++) {
              lines.push(parts[i]);
              console.log(`â€¢ ${parts[i]}`);
  for await (const event of stream3) {
    switch (event.type) {
      case 'output_text_delta':
        currentLine += event.delta;
        // Process line by line
        if (event.delta.includes('\n')) {
          const parts = currentLine.split('\n');
          // Add all but the last part (which might be incomplete)
          for (let i = 0; i < parts.length - 1; i++) {
            if (parts[i]!.trim()) {
              lines.push(parts[i]!);
              console.log(`  ${lines.length}. ${parts[i]!.trim()}`);
            }
            currentLine = parts[parts.length - 1];
          }
          break;

        case 'output_text_done':
          if (currentLine.trim()) {
            lines.push(currentLine.trim());
            console.log(`â€¢ ${currentLine.trim()}`);
          }
          console.log('\nâœ“ Completed custom processing');
          break;

        case 'response_done':
          console.log('\nðŸ“„ Structured Summary:');
          lines.forEach((line, index) => {
            console.log(`  ${index + 1}. ${line}`);
          });
          break;
      }
    }

    console.log('\nâœ“ Example 3 completed');
  } else {
    console.log('Skipping Example 3 due to a connection issue.');
  }


  // ============================================================================
  // Example 4: Error Handling in Streaming
  // ============================================================================
  console.log('\n\nExample 4: Error Handling in Streaming');
  console.log('â”€'.repeat(60));

  const errorHandlingAgent = new Agent({
    name: 'ErrorHandlingAgent',
    model: codexModel,
    instructions: 'You are a helpful assistant.',
  });

  console.log('\nQuery: "Explain error handling in streaming"\n');
  console.log('[Error Handling]\n');

  const stream4 = await runExampleStep('Error handling streaming run', () =>
    run(errorHandlingAgent, 'Explain error handling in streaming')
  const stream4 = await run(
    errorHandlingAgent,
    'Explain error handling in streaming',
    { stream: true }
  );

  if (stream4) {
    let hasError = false;

    try {
      for await (const event of stream4.events) {
        switch (event.type) {
          case 'output_text_delta':
            process.stdout.write(event.delta);
            break;
  try {
    for await (const event of stream4) {
      switch (event.type) {
        case 'output_text_delta':
          process.stdout.write(event.delta);
          break;

          case 'error':
            hasError = true;
            console.error('\n\nâœ— Streaming error:', event.error.message);
            break;

          case 'response_done':
            if (!hasError) {
              console.log('\n\nâœ“ Stream completed successfully');
            }
            break;
        }
      }
    } catch (error) {
      console.error(
        '\n\nâœ— Fatal error during streaming:',
        error instanceof Error ? error.message : String(error),
      );
    }

    console.log('\nâœ“ Example 4 completed');
  } else {
    console.log('Skipping Example 4 due to a connection issue.');
  }

  // ============================================================================
  // Summary
  // ============================================================================
  console.log('\n\n' + '='.repeat(60));
  console.log('ðŸ“‹ Summary');
  console.log('='.repeat(60));
  console.log('\nKey takeaways:');
  console.log('  â€¢ Streaming provides real-time updates as responses are generated');
  console.log('  â€¢ Use run() to obtain StreamedRunResult for streaming flows');
  console.log('  â€¢ Call run(agent, input, { stream: true }) to enable streaming');
  console.log('  â€¢ Handle different event types: deltas, done, errors');
  console.log('  â€¢ CodexProvider supports full streaming capabilities');
  console.log('  â€¢ Streaming enables better UX with progress indicators');
  console.log('\nStream event types:');
  console.log('  â€¢ response_started - Stream began');
  console.log('  â€¢ output_text_delta - Text chunk received');
  console.log('  â€¢ output_text_done - Text output completed');
  console.log('  â€¢ reasoning_delta - Reasoning chunk (if supported)');
  console.log('  â€¢ reasoning_done - Reasoning completed');
  console.log('  â€¢ response_done - Full response with usage stats');
  console.log('  â€¢ error - Error occurred');
  console.log('\nFor more information, see:');
  console.log('  https://openai.github.io/openai-agents-js/guides/streaming');

  // Cleanup
  try {
    await fs.rm(tmpDir, { recursive: true, force: true });
  } catch (e) {
    // Ignore cleanup errors
  }
}

// Run if executed directly
if (require.main === module) {
  main()
    .then(() => {
      process.exit(0);
    })
    .catch((error) => {
      console.error('Fatal error:', error);
      process.exit(1);
    });
}

export { main };

